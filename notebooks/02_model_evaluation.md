# 02 â€“ Model Evaluation

Purpose:
- Summarize teacher, student baseline, and distilled student performance.
- Aggregate metrics from multiple runs and visualize training curves or confusion matrices.
- Document qualitative assessments (e.g., misclassified examples, saliency maps) to guide iteration.

Checklist:
- [ ] Load evaluation artifacts from `logs/` or exported metrics files.
- [ ] Compare performance across experiment configurations.
- [ ] Highlight next steps for improving student generalization.
